{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_class\n",
    "import pandas as pd\n",
    "import requests,os,time\n",
    "from datetime import datetime\n",
    "\n",
    "logfile=\"tripadvisor.txt\"\n",
    "Connector = scraping_class.Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,os,time\n",
    "\n",
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(1) # sleep one second.\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='requests',session=False,path2selenium='',n_tries = 5,timeout=30):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring. \n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessments\n",
    "    \n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case). \n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver \n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Firefox(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "    \n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\n",
    "    header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "    if os.path.isfile(logfile):        \n",
    "      if overwrite_log==True:\n",
    "        self.log = open(logfile,'w')\n",
    "        self.log.write(';'.join(header))\n",
    "      else:\n",
    "        self.log = open(logfile,'a')\n",
    "    else:\n",
    "      self.log = open(logfile,'w')\n",
    "      self.log.write(';'.join(header))\n",
    "    ## load log \n",
    "    with open(logfile,'r') as f: # open file\n",
    "        \n",
    "      l = f.read().split('\\n') # read and split file by newlines.\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1][0])+1\n",
    "            \n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, Name used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    "     \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit()\n",
    "        t = time.time()\n",
    "        try: # error handling \n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = t - time.time() # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          call_id = self.id # get current unique identifier for the call\n",
    "          self.id+=1 # increment call id\n",
    "          #['id','project_name','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row to be written in the log.\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write log.\n",
    "          return response,call_id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt = t - time.time() # define delta t\n",
    "\n",
    "          ## log...\n",
    "          call_id = self.id # define unique identifier\n",
    "          self.id+=1 # increment call_id\n",
    "\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write row to log.\n",
    "    else:\n",
    "      t = time.time()\n",
    "      ratelimit()\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      ## log\n",
    "      call_id = self.id # define unique identifier for the call. \n",
    "      self.id+=1 # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = t - time.time() # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row \n",
    "      self.log.write('\\n'+';'.join(map(str,row))) # write row to log file.\n",
    "    # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "    ## connector.browser.page_source will give you the html.\n",
    "      return call_id\n",
    "    \n",
    "\n",
    "logfile=\"tripadvisor_loader.txt\" ## name your log file.\n",
    "connector = Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 2019-08-23 09:13:24.978958\n",
      "True 2019-08-23 09:13:27.731017\n",
      "True 2019-08-23 09:13:31.055618\n",
      "True 2019-08-23 09:13:33.721025\n",
      "True 2019-08-23 09:13:35.944077\n",
      "True 2019-08-23 09:13:37.984130\n",
      "True 2019-08-23 09:13:40.248630\n",
      "True 2019-08-23 09:13:42.190765\n",
      "True 2019-08-23 09:13:44.550856\n",
      "True 2019-08-23 09:13:46.998034\n",
      "True 2019-08-23 09:13:49.463783\n",
      "True 2019-08-23 09:13:51.458581\n",
      "True 2019-08-23 09:13:54.067751\n",
      "True 2019-08-23 09:13:56.319765\n",
      "True 2019-08-23 09:13:58.495329\n",
      "True 2019-08-23 09:14:02.055627\n",
      "True 2019-08-23 09:14:04.304940\n",
      "True 2019-08-23 09:14:06.455761\n",
      "True 2019-08-23 09:14:08.912336\n",
      "True 2019-08-23 09:14:11.061813\n",
      "True 2019-08-23 09:14:13.216175\n",
      "True 2019-08-23 09:14:15.106166\n",
      "True 2019-08-23 09:14:17.514915\n",
      "True 2019-08-23 09:14:19.717131\n",
      "True 2019-08-23 09:14:21.946433\n",
      "True 2019-08-23 09:14:24.274460\n",
      "True 2019-08-23 09:14:26.422269\n",
      "True 2019-08-23 09:14:28.581142\n",
      "True 2019-08-23 09:14:31.030745\n",
      "True 2019-08-23 09:14:33.183204\n",
      "True 2019-08-23 09:14:35.415884\n",
      "True 2019-08-23 09:14:37.604237\n",
      "True 2019-08-23 09:14:39.708173\n",
      "True 2019-08-23 09:14:41.963356\n",
      "True 2019-08-23 09:14:43.905183\n",
      "True 2019-08-23 09:14:46.392028\n",
      "True 2019-08-23 09:14:48.554858\n",
      "True 2019-08-23 09:14:50.727053\n",
      "True 2019-08-23 09:14:53.968167\n",
      "True 2019-08-23 09:14:56.236851\n",
      "True 2019-08-23 09:14:58.637582\n",
      "True 2019-08-23 09:15:00.727260\n",
      "True 2019-08-23 09:15:03.180861\n",
      "True 2019-08-23 09:15:05.455596\n",
      "True 2019-08-23 09:15:07.404609\n",
      "True 2019-08-23 09:15:09.635423\n",
      "True 2019-08-23 09:15:11.784688\n",
      "True 2019-08-23 09:15:13.653658\n",
      "True 2019-08-23 09:15:15.776253\n",
      "True 2019-08-23 09:15:17.697945\n",
      "True 2019-08-23 09:15:20.081464\n",
      "True 2019-08-23 09:15:22.545299\n",
      "True 2019-08-23 09:15:24.991482\n",
      "True 2019-08-23 09:15:27.151607\n",
      "True 2019-08-23 09:15:30.536256\n",
      "True 2019-08-23 09:15:32.677145\n",
      "True 2019-08-23 09:15:34.604716\n",
      "True 2019-08-23 09:15:36.729609\n",
      "True 2019-08-23 09:15:38.827714\n",
      "True 2019-08-23 09:15:40.867954\n",
      "True 2019-08-23 09:15:43.091327\n",
      "True 2019-08-23 09:15:45.297547\n",
      "True 2019-08-23 09:15:47.421465\n",
      "True 2019-08-23 09:15:51.022771\n",
      "True 2019-08-23 09:15:53.274720\n",
      "True 2019-08-23 09:15:55.406989\n",
      "True 2019-08-23 09:15:57.626838\n",
      "True 2019-08-23 09:16:01.091105\n",
      "True 2019-08-23 09:16:02.991756\n",
      "True 2019-08-23 09:16:04.871297\n",
      "True 2019-08-23 09:16:06.825622\n",
      "True 2019-08-23 09:16:08.631447\n",
      "True 2019-08-23 09:16:10.702495\n",
      "True 2019-08-23 09:16:13.022004\n",
      "True 2019-08-23 09:16:14.923445\n",
      "True 2019-08-23 09:16:17.013342\n",
      "True 2019-08-23 09:16:18.890135\n",
      "True 2019-08-23 09:16:20.988267\n"
     ]
    }
   ],
   "source": [
    "url_init = 'https://www.tripadvisor.com' # base url\n",
    "max_restaurant = 2322\n",
    "init_number = 0\n",
    "final_urls = []\n",
    "timestamp = datetime.now()\n",
    "year = timestamp.year\n",
    "month = timestamp.month\n",
    "day = timestamp.day\n",
    "\n",
    "\n",
    "while init_number <= max_restaurant:\n",
    "    timestamp = datetime.now() # Creates a timestamp in the format yyyy-mm-dd h:m:s\n",
    "    \n",
    "    url_search = '/RestaurantSearch-g189541-o' # first part of url\n",
    "    url_search2 = '-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS' # second part of url\n",
    "    url_search3 = url_init + url_search + str(init_number) + url_search2 # combined dynamic url\n",
    "    data, call_id = connector.get(url_search3, 'exam') # gathering data\n",
    "    response = data.ok # check if data is available\n",
    "    print(response, timestamp) # prints response and timestamp of call.\n",
    "    final_urls.append(url_search3)\n",
    "    init_number += 30 # incriments the number by 30 to be put into the url next call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "78\n",
      "                                                                                                                                                                                      0\n",
      "0      https://www.tripadvisor.com/RestaurantSearch-g189541-o0-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "1     https://www.tripadvisor.com/RestaurantSearch-g189541-o30-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "2     https://www.tripadvisor.com/RestaurantSearch-g189541-o60-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "3     https://www.tripadvisor.com/RestaurantSearch-g189541-o90-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "4    https://www.tripadvisor.com/RestaurantSearch-g189541-o120-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "5    https://www.tripadvisor.com/RestaurantSearch-g189541-o150-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "6    https://www.tripadvisor.com/RestaurantSearch-g189541-o180-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "7    https://www.tripadvisor.com/RestaurantSearch-g189541-o210-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "8    https://www.tripadvisor.com/RestaurantSearch-g189541-o240-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "9    https://www.tripadvisor.com/RestaurantSearch-g189541-o270-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "10   https://www.tripadvisor.com/RestaurantSearch-g189541-o300-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "11   https://www.tripadvisor.com/RestaurantSearch-g189541-o330-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "12   https://www.tripadvisor.com/RestaurantSearch-g189541-o360-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "13   https://www.tripadvisor.com/RestaurantSearch-g189541-o390-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "14   https://www.tripadvisor.com/RestaurantSearch-g189541-o420-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "15   https://www.tripadvisor.com/RestaurantSearch-g189541-o450-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "16   https://www.tripadvisor.com/RestaurantSearch-g189541-o480-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "17   https://www.tripadvisor.com/RestaurantSearch-g189541-o510-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "18   https://www.tripadvisor.com/RestaurantSearch-g189541-o540-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "19   https://www.tripadvisor.com/RestaurantSearch-g189541-o570-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "20   https://www.tripadvisor.com/RestaurantSearch-g189541-o600-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "21   https://www.tripadvisor.com/RestaurantSearch-g189541-o630-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "22   https://www.tripadvisor.com/RestaurantSearch-g189541-o660-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "23   https://www.tripadvisor.com/RestaurantSearch-g189541-o690-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "24   https://www.tripadvisor.com/RestaurantSearch-g189541-o720-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "25   https://www.tripadvisor.com/RestaurantSearch-g189541-o750-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "26   https://www.tripadvisor.com/RestaurantSearch-g189541-o780-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "27   https://www.tripadvisor.com/RestaurantSearch-g189541-o810-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "28   https://www.tripadvisor.com/RestaurantSearch-g189541-o840-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "29   https://www.tripadvisor.com/RestaurantSearch-g189541-o870-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "..                                                                                                                                                                                  ...\n",
      "48  https://www.tripadvisor.com/RestaurantSearch-g189541-o1440-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "49  https://www.tripadvisor.com/RestaurantSearch-g189541-o1470-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "50  https://www.tripadvisor.com/RestaurantSearch-g189541-o1500-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "51  https://www.tripadvisor.com/RestaurantSearch-g189541-o1530-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "52  https://www.tripadvisor.com/RestaurantSearch-g189541-o1560-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "53  https://www.tripadvisor.com/RestaurantSearch-g189541-o1590-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "54  https://www.tripadvisor.com/RestaurantSearch-g189541-o1620-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "55  https://www.tripadvisor.com/RestaurantSearch-g189541-o1650-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "56  https://www.tripadvisor.com/RestaurantSearch-g189541-o1680-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "57  https://www.tripadvisor.com/RestaurantSearch-g189541-o1710-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "58  https://www.tripadvisor.com/RestaurantSearch-g189541-o1740-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "59  https://www.tripadvisor.com/RestaurantSearch-g189541-o1770-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "60  https://www.tripadvisor.com/RestaurantSearch-g189541-o1800-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "61  https://www.tripadvisor.com/RestaurantSearch-g189541-o1830-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "62  https://www.tripadvisor.com/RestaurantSearch-g189541-o1860-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "63  https://www.tripadvisor.com/RestaurantSearch-g189541-o1890-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "64  https://www.tripadvisor.com/RestaurantSearch-g189541-o1920-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "65  https://www.tripadvisor.com/RestaurantSearch-g189541-o1950-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "66  https://www.tripadvisor.com/RestaurantSearch-g189541-o1980-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "67  https://www.tripadvisor.com/RestaurantSearch-g189541-o2010-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "68  https://www.tripadvisor.com/RestaurantSearch-g189541-o2040-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "69  https://www.tripadvisor.com/RestaurantSearch-g189541-o2070-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "70  https://www.tripadvisor.com/RestaurantSearch-g189541-o2100-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "71  https://www.tripadvisor.com/RestaurantSearch-g189541-o2130-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "72  https://www.tripadvisor.com/RestaurantSearch-g189541-o2160-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "73  https://www.tripadvisor.com/RestaurantSearch-g189541-o2190-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "74  https://www.tripadvisor.com/RestaurantSearch-g189541-o2220-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "75  https://www.tripadvisor.com/RestaurantSearch-g189541-o2250-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "76  https://www.tripadvisor.com/RestaurantSearch-g189541-o2280-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "77  https://www.tripadvisor.com/RestaurantSearch-g189541-o2310-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS\n",
      "\n",
      "[78 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(init_number)\n",
    "print(len(final_urls))\n",
    "df = pd.DataFrame(final_urls)\n",
    "pd.options.display.max_colwidth = 200\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Init_links']\n",
    "df.to_csv('export_dataframe.csv', index = None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
