{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_class\n",
    "import pandas as pd\n",
    "import requests,os,time, re\n",
    "from datetime import datetime\n",
    "from time import gmtime, strftime\n",
    "import bs4 as bs\n",
    "from urllib.request import urlopen as ureq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import urllib.request\n",
    "from geopy.distance import great_circle\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running of connector for HTML scraper - Created by Snorre Raslund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(0.5) # sleep one second.\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='requests',session=False,path2selenium='',n_tries = 5,timeout=30):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring.\n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessment\n",
    "    \n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case).\n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver \n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Firefox(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "\n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\\n\",\n",
    "    header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "    if os.path.isfile(logfile):        \n",
    "      if overwrite_log==True:\n",
    "        self.log = open(logfile,'w')\n",
    "        self.log.write(';'.join(header))\n",
    "      else:\n",
    "        self.log = open(logfile,'a')\n",
    "    else:\n",
    "      self.log = open(logfile,'w')\n",
    "      self.log.write(';'.join(header))\n",
    "    ## load log \n",
    "    with open(logfile,'r') as f: # open file\n",
    "        \n",
    "      l = f.read().split('\\\\n') # read and split file by newlines.\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1][0])+1\n",
    "           \n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "  \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, Name used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    " \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit()\n",
    "        t = time.time()\n",
    "        try: # error handling \n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = t - time.time() # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          call_id = self.id # get current unique identifier for the call\n",
    "          self.id+=1 # increment call id\n",
    "          #['id','project_name','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row to be written in the log.\n",
    "          self.log.write('\\\\n'+';'.join(map(str,row))) # write log.\n",
    "          return response,call_id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt = t - time.time() # define delta t\n",
    "\n",
    "          ## log...\n",
    "          call_id = self.id # define unique identifier\n",
    "          self.id+=1 # increment call_id\n",
    "\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row\n",
    "          self.log.write('\\\\n'+';'.join(map(str,row))) # write row to log.\n",
    "    else:\n",
    "      t = time.time()\n",
    "      ratelimit()\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      ## log\n",
    "      call_id = self.id # define unique identifier for the call.\n",
    "      self.id+=1 # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = t - time.time() # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row \n",
    "      self.log.write('\\\\n'+';'.join(map(str,row))) # write row to log file.\n",
    "    # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "    ## connector.browser.page_source will give you the html.\n",
    "      return call_id\n",
    "\n",
    "logfile=\"tripadvisor_scraper.txt\" # name your log file.\n",
    "connector = Connector(logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML scraper - 1 step\n",
    "The below code gets an overview of all the restaurant in the Copenhagen area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Ok Timestamp: 2019-08-27 12:29:56 links processed: 1\n",
      "Status: Ok Timestamp: 2019-08-27 12:29:58 links processed: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-74400fd9ed3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0murl_search2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'-a_date.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'__2D__'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'__2D__'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-a_people.2-a_time.20%3A00%3A00-a_zur.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'__5F__'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'__5F__'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-Copenhag.html'\u001b[0m \u001b[0;31m# second part of url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0murl_search3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_init\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl_search\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_number\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl_search2\u001b[0m \u001b[0;31m# combined dynamic url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_search3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exam_init'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gathering data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m \u001b[0;31m# checks if datastream is possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfinal_urls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_search3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-71ab58cc76ad>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, project_name)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'requests'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Determine connector method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# for loop defining number of retries with the requests method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mratelimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# error handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-71ab58cc76ad>\u001b[0m in \u001b[0;36mratelimit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mratelimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"A function that handles the rate of your calls.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sleep one second.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url_init = 'https://www.tripadvisor.dk' # TripAdvisor base url\n",
    "max_restaurant = 2324 # Restaurants stated on he webpage, to be located in Copenhangen area\n",
    "init_number = 0 \n",
    "final_urls = []\n",
    "year = datetime.now().year\n",
    "month = datetime.now().month\n",
    "day = datetime.now().day\n",
    "\n",
    "\n",
    "while init_number <= max_restaurant:\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S') # Creates a timestamp in the format yyyy-mm-dd h:m:s\n",
    "    \n",
    "    url_search = '/RestaurantSearch-g189541-o' # first part of url\n",
    "    url_search2 = '-a_date.' + str(year) + '__2D__' + str(month) + '__2D__' + str(day) + '-a_people.2-a_time.20%3A00%3A00-a_zur.' + str(year) + '__5F__' + str(month) + '__5F__' + str(day) + '-Copenhag.html' # second part of url\n",
    "    url_search3 = url_init + url_search + str(init_number) + url_search2 # combined dynamic url\n",
    "    data, call_id = connector.get(url_search3, 'exam_init') # gathering data\n",
    "    response = data.ok # checks if datastream is possible\n",
    "    final_urls.append(url_search3)\n",
    "    if response == True:\n",
    "        status = 'Ok'\n",
    "\n",
    "    print('Status:', status , 'Timestamp:', timestamp, 'links processed:', len(final_urls)) # prints response, timestamp and amount of links processed.\n",
    "    init_number += 30 # incriments the number by 30 to be put into the url on next call.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(init_number)\n",
    "print(len(final_urls))\n",
    "overview_urls = pd.DataFrame(final_urls)\n",
    "pd.options.display.max_colwidth = 200\n",
    "print(overview_urls.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_urls.columns = ['Init_links']\n",
    "overview_urls.to_csv('overview_urls.csv', index = None, header = True) # writes data from df to csv file a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML scraper - 2 step\n",
    "The code below takes the links generated in step 1 as input, and gives us the individual links to all the restaurants in the Copenhagen area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_list = []\n",
    "\n",
    "for url in final_urls: # loops over all overview sites\n",
    "    response,call_id = connector.get(url,'exam_links')\n",
    "    link_locations = response.text.split('href=\"')[1:] # find all links on site \n",
    "    link_list = [] \n",
    "    \n",
    "    for i in link_locations:\n",
    "        if \"Restaurant_Review\" in i: # finds all links named something with Restaurant review\n",
    "            link_list.append(i.partition(\" \")[0])\n",
    "\n",
    "        review_list=  []\n",
    "    for i in link_list:\n",
    "        if \"Restaurant_Review\" in i and \"#REVIEWS\" not in i and \"button\" not in i: # same links appart from this removes two alternative versions and only stores one.\n",
    "            review_list.append(i)\n",
    "\n",
    "            review_list_u = set(review_list) # remove dublicates\n",
    "\n",
    "    for i in review_list_u:\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S') # Creates a timestamp in the format yyyy-mm-dd h:m:s\n",
    "        page_list.append(url_init+i) # make list of final urls\n",
    "        if response == True:\n",
    "            status = 'Ok'\n",
    "        \n",
    "        print('Status:', status , 'Timestamp:', timestamp, 'links processed:', len(page_list)) # prints response, timestamp and amount of links processed.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(page_list))\n",
    "indvidual_urls = pd.DataFrame(page_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indvidual_urls.columns = ['Restaurant_links']\n",
    "indvidual_urls.to_csv('indvidual_urls.csv', index = None, header = True) # writes df to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML scraper - step 3\n",
    "The below code takes the links for step 2 as input and retreives all the data that we ask for, for the individual restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading urls from csv\n",
    "df_urls = pd.read_csv(\"indvidual_urls.csv\")\n",
    "ratings_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Creating empty lists to store data in\n",
    "loc_list = []\n",
    "reviewCount_list = []\n",
    "distance_list = []\n",
    "unique_list = []\n",
    "price_class_list = []\n",
    "main_rating_list = []\n",
    "ranking_list = []\n",
    "price_class_value_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Ok Timestamp: 2019-08-27 15:20:44 pages scraped: 1\n",
      "Status: Ok Timestamp: 2019-08-27 15:20:47 pages scraped: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelemcken/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Ok Timestamp: 2019-08-27 15:20:51 pages scraped: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelemcken/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Ok Timestamp: 2019-08-27 15:20:55 pages scraped: 4\n",
      "Status: Ok Timestamp: 2019-08-27 15:20:58 pages scraped: 5\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:03 pages scraped: 6\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:07 pages scraped: 7\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:11 pages scraped: 8\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:15 pages scraped: 9\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:18 pages scraped: 10\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:23 pages scraped: 11\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:26 pages scraped: 12\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:29 pages scraped: 13\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:32 pages scraped: 14\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:35 pages scraped: 15\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:38 pages scraped: 16\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:41 pages scraped: 17\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:44 pages scraped: 18\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:47 pages scraped: 19\n",
      "Status: Ok Timestamp: 2019-08-27 15:21:51 pages scraped: 20\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:00 pages scraped: 21\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:04 pages scraped: 22\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:07 pages scraped: 23\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:11 pages scraped: 24\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:14 pages scraped: 25\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:18 pages scraped: 26\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:22 pages scraped: 27\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:26 pages scraped: 28\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:30 pages scraped: 29\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:33 pages scraped: 30\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:37 pages scraped: 31\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:40 pages scraped: 32\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:44 pages scraped: 33\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:48 pages scraped: 34\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:52 pages scraped: 35\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:55 pages scraped: 36\n",
      "Status: Ok Timestamp: 2019-08-27 15:22:59 pages scraped: 37\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:03 pages scraped: 38\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:07 pages scraped: 39\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:10 pages scraped: 40\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:15 pages scraped: 41\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:19 pages scraped: 42\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:23 pages scraped: 43\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:26 pages scraped: 44\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:30 pages scraped: 45\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:34 pages scraped: 46\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:38 pages scraped: 47\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:41 pages scraped: 48\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:45 pages scraped: 49\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:49 pages scraped: 50\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:52 pages scraped: 51\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:56 pages scraped: 52\n",
      "Status: Ok Timestamp: 2019-08-27 15:23:59 pages scraped: 53\n",
      "Status: Ok Timestamp: 2019-08-27 15:24:03 pages scraped: 54\n",
      "Status: Ok Timestamp: 2019-08-27 15:24:07 pages scraped: 55\n",
      "Status: Ok Timestamp: 2019-08-27 15:24:11 pages scraped: 56\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:15 pages scraped: 57\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:20 pages scraped: 58\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:23 pages scraped: 59\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:27 pages scraped: 60\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:31 pages scraped: 61\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:34 pages scraped: 62\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:38 pages scraped: 63\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:43 pages scraped: 64\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:46 pages scraped: 65\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:50 pages scraped: 66\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:53 pages scraped: 67\n",
      "Status: Ok Timestamp: 2019-08-27 15:26:57 pages scraped: 68\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:00 pages scraped: 69\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:04 pages scraped: 70\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:07 pages scraped: 71\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:12 pages scraped: 72\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:18 pages scraped: 73\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:23 pages scraped: 74\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:27 pages scraped: 75\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:30 pages scraped: 76\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:34 pages scraped: 77\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:37 pages scraped: 78\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:41 pages scraped: 79\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:46 pages scraped: 80\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:50 pages scraped: 81\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:53 pages scraped: 82\n",
      "Status: Ok Timestamp: 2019-08-27 15:27:57 pages scraped: 83\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:01 pages scraped: 84\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:04 pages scraped: 85\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:08 pages scraped: 86\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:11 pages scraped: 87\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:17 pages scraped: 88\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:22 pages scraped: 89\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:26 pages scraped: 90\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:29 pages scraped: 91\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:32 pages scraped: 92\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:36 pages scraped: 93\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:39 pages scraped: 94\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:42 pages scraped: 95\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:50 pages scraped: 96\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:53 pages scraped: 97\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:55 pages scraped: 98\n",
      "Status: Ok Timestamp: 2019-08-27 15:28:58 pages scraped: 99\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:02 pages scraped: 100\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:06 pages scraped: 101\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:10 pages scraped: 102\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:14 pages scraped: 103\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:17 pages scraped: 104\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:21 pages scraped: 105\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:25 pages scraped: 106\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:28 pages scraped: 107\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:32 pages scraped: 108\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:35 pages scraped: 109\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:39 pages scraped: 110\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:42 pages scraped: 111\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:46 pages scraped: 112\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:49 pages scraped: 113\n",
      "Status: Ok Timestamp: 2019-08-27 15:29:52 pages scraped: 114\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:11 pages scraped: 115\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:14 pages scraped: 116\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:17 pages scraped: 117\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:20 pages scraped: 118\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:22 pages scraped: 119\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:25 pages scraped: 120\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:29 pages scraped: 121\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:32 pages scraped: 122\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:36 pages scraped: 123\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:40 pages scraped: 124\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:44 pages scraped: 125\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:48 pages scraped: 126\n",
      "Status: Ok Timestamp: 2019-08-27 15:30:56 pages scraped: 127\n",
      "Status: Ok Timestamp: 2019-08-27 15:31:00 pages scraped: 128\n",
      "Status: Ok Timestamp: 2019-08-27 15:31:05 pages scraped: 129\n",
      "Status: Ok Timestamp: 2019-08-27 15:31:09 pages scraped: 130\n",
      "Status: Ok Timestamp: 2019-08-27 15:31:13 pages scraped: 131\n",
      "Status: Ok Timestamp: 2019-08-27 15:31:18 pages scraped: 132\n",
      "Status: Ok Timestamp: 2019-08-27 15:31:23 pages scraped: 133\n",
      "Status: Ok Timestamp: 2019-08-27 15:33:32 pages scraped: 134\n",
      "Status: Ok Timestamp: 2019-08-27 15:33:40 pages scraped: 135\n",
      "Status: Ok Timestamp: 2019-08-27 15:33:47 pages scraped: 136\n",
      "Status: Ok Timestamp: 2019-08-27 15:33:49 pages scraped: 137\n",
      "Status: Ok Timestamp: 2019-08-27 15:33:52 pages scraped: 138\n",
      "Status: Ok Timestamp: 2019-08-27 15:33:55 pages scraped: 139\n",
      "Status: Ok Timestamp: 2019-08-27 15:33:57 pages scraped: 140\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:00 pages scraped: 141\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:05 pages scraped: 142\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:08 pages scraped: 143\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:11 pages scraped: 144\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:13 pages scraped: 145\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:16 pages scraped: 146\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:18 pages scraped: 147\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:21 pages scraped: 148\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:31 pages scraped: 149\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:34 pages scraped: 150\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:36 pages scraped: 151\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:39 pages scraped: 152\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:42 pages scraped: 153\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:45 pages scraped: 154\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:48 pages scraped: 155\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:51 pages scraped: 156\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:54 pages scraped: 157\n",
      "Status: Ok Timestamp: 2019-08-27 15:34:57 pages scraped: 158\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:01 pages scraped: 159\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:04 pages scraped: 160\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:07 pages scraped: 161\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:10 pages scraped: 162\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:14 pages scraped: 163\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:18 pages scraped: 164\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:26 pages scraped: 165\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:29 pages scraped: 166\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:33 pages scraped: 167\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:37 pages scraped: 168\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:42 pages scraped: 169\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:45 pages scraped: 170\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:49 pages scraped: 171\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:53 pages scraped: 172\n",
      "Status: Ok Timestamp: 2019-08-27 15:35:57 pages scraped: 173\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:01 pages scraped: 174\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:05 pages scraped: 175\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:09 pages scraped: 176\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:12 pages scraped: 177\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:16 pages scraped: 178\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:21 pages scraped: 179\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:25 pages scraped: 180\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:29 pages scraped: 181\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:32 pages scraped: 182\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:35 pages scraped: 183\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:39 pages scraped: 184\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:43 pages scraped: 185\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:47 pages scraped: 186\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:50 pages scraped: 187\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:54 pages scraped: 188\n",
      "Status: Ok Timestamp: 2019-08-27 15:36:57 pages scraped: 189\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:00 pages scraped: 190\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:05 pages scraped: 191\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:08 pages scraped: 192\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:12 pages scraped: 193\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:17 pages scraped: 194\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:20 pages scraped: 195\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:24 pages scraped: 196\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:27 pages scraped: 197\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:31 pages scraped: 198\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:35 pages scraped: 199\n",
      "Status: Ok Timestamp: 2019-08-27 15:37:40 pages scraped: 200\n"
     ]
    }
   ],
   "source": [
    "#giant for loop\n",
    "for url in df_urls[\"Restaurant_links\"][1000:1200]:\n",
    "\n",
    "    trip = ureq(url)\n",
    "    trip_html = trip.read()\n",
    "    trip.close()\n",
    "    trip_soup = soup(trip_html, \"lxml\")\n",
    "    if len(trip_soup.text) > 0:\n",
    "        status = 'Ok'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        print(status)\n",
    "    \n",
    "    \n",
    "    test = trip_soup.findAll(True, {\"class\":[\"restaurants-detail-overview-cards-RatingsOverviewCard__ratingText--1P1Lq\", \"restaurants-detail-overview-cards-RatingsOverviewCard__ratingBubbles--1kQYC\"]})\n",
    "    name = trip_soup.findAll(True, {\"class\":[\"ui_header h1\"]})\n",
    "    name = str(name)\n",
    "    name = name[26:]\n",
    "    name = name.replace(\"</h1>]\", '')\n",
    "      \n",
    "    elements = []\n",
    "    for x in test:\n",
    "        elements.append(str(x))\n",
    "    \n",
    "    keys = elements[0::2]\n",
    "    values = elements[1::2]\n",
    "    keys.append(\"Name\")\n",
    "    values.append(str(name))\n",
    "\n",
    "    keys[:] = [s.replace('<span class=\"restaurants-detail-overview-cards-RatingsOverviewCard__ratingText--1P1Lq\">', '') for s in keys]\n",
    "    keys[:] = [s.replace('</span>', '') for s in keys]\n",
    "    values[:] = [s.replace('<span class=\"restaurants-detail-overview-cards-RatingsOverviewCard__ratingBubbles--1kQYC\"><span class=\"ui_bubble_rating bubble_', '') for s in values]\n",
    "    values[:] = [s.replace('\"></span></span>', '') for s in values]\n",
    "    \n",
    "    ratings_dict = {}\n",
    "    for i in range(len(keys)):\n",
    "        ratings_dict[keys[i]] = values[i]\n",
    "    \n",
    "    #append\n",
    "    ratings_df = ratings_df.append([ratings_dict], ignore_index=True)    \n",
    "    \n",
    "    #Najas location loop\n",
    "    p = re.compile(r'\"coords\":\"(.*?)\"')\n",
    "    r = requests.get(url)\n",
    "    coords = p.findall(r.text)[1]\n",
    "    loc_list.append(coords)\n",
    "    \n",
    "    #Naja review count\n",
    "    reviewCount = str(trip_soup.find(class_=\"reviewCount\"))\n",
    "    reviewCount = reviewCount.split(\">\")[1].split(\"<\")[0]\n",
    "    reviewCount_list.append(reviewCount)\n",
    "    \n",
    "    #Exstracting price_class_number $$$\n",
    "    price_class_number = str(trip_soup.find('div', class_=\"header_links\"))\n",
    "    price_class = re.sub('[^$-]', '', price_class_number)\n",
    "    price_class_list.append(price_class)\n",
    "\n",
    "    #Exstracting number of bubbles\n",
    "    bubbles = str(trip_soup.find(class_=\"restaurants-detail-overview-cards-RatingsOverviewCard__overallRating--nohTl\"))    \n",
    "    main_rating = re.sub('[^0-9,.]', '', bubbles) #stripping all other than the ranking numbers\n",
    "    main_rating_list.append(main_rating)\n",
    "    \n",
    "    #Exstracting list_ranking\n",
    "    list_ranking =str(trip_soup.find(class_=\"restaurants-detail-overview-cards-RatingsOverviewCard__ranking--17CmN\").find('span', class_=\"\"))\n",
    "    ranking = re.sub('[^0-9,]', '', list_ranking)\n",
    "    ranking_list.append(ranking)\n",
    "    \n",
    "    #Exstracting price_class_value\n",
    "    price_class_value = str(trip_soup.find(class_=\"restaurants-detail-overview-cards-DetailsSectionOverviewCard__tagText--1OH6h\"))\n",
    "    price_class_value = re.sub('[^0-9,.-]', '', price_class_value)\n",
    "    price_class_value_list.append(price_class_value)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    print('Status:', status , 'Timestamp:', timestamp, 'pages scraped:', len(ratings_df)) # prints response, timestamp and amount of links processed.\n",
    "        \n",
    "    \n",
    "#out of loop\n",
    "ratings_df[\"Location\"] = loc_list\n",
    "ratings_df[\"Number of reviews\"] = reviewCount_list\n",
    "ratings_df[\"Price class\"] = price_class_list\n",
    "ratings_df[\"Main rating\"] = main_rating_list\n",
    "ratings_df[\"Ranking on list\"] = ranking_list\n",
    "ratings_df[\"Price range\"] = price_class_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>God pris</th>\n",
       "      <th>Mad</th>\n",
       "      <th>Name</th>\n",
       "      <th>Service</th>\n",
       "      <th>Stemning</th>\n",
       "      <th>Location</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Price class</th>\n",
       "      <th>Main rating</th>\n",
       "      <th>Ranking on list</th>\n",
       "      <th>Price range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>Bistro Central</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.68168,12.582247</td>\n",
       "      <td>50 anmeldelser</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>973</td>\n",
       "      <td>------1654.-448.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>Louises Fiskebar</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.677296,12.567593</td>\n",
       "      <td>20 anmeldelser</td>\n",
       "      <td>--$$$$---</td>\n",
       "      <td>4,5</td>\n",
       "      <td>987</td>\n",
       "      <td>------1674.-696.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>Café René</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>55.676224,12.56407</td>\n",
       "      <td>52 anmeldelser</td>\n",
       "      <td>--$$-$$$---------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>980</td>\n",
       "      <td>------16,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Herkules Pavillonen</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.68627,12.580382</td>\n",
       "      <td>10 anmeldelser</td>\n",
       "      <td>--$$-$$$</td>\n",
       "      <td>4,5</td>\n",
       "      <td>981</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>Galathea Kroen</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.6766,12.57455</td>\n",
       "      <td>34 anmeldelser</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>964</td>\n",
       "      <td>------16120.-221.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  God pris Mad                 Name Service Stemning             Location  \\\n",
       "0       40  40       Bistro Central      45      NaN   55.68168,12.582247   \n",
       "1       35  40     Louises Fiskebar      45      NaN  55.677296,12.567593   \n",
       "2       35  35            Café René      40       40   55.676224,12.56407   \n",
       "3       40  45  Herkules Pavillonen      45      NaN   55.68627,12.580382   \n",
       "4       35  35       Galathea Kroen      35      NaN     55.6766,12.57455   \n",
       "\n",
       "  Number of reviews        Price class Main rating Ranking on list  \\\n",
       "0    50 anmeldelser     --$$-$$$------         4,0             973   \n",
       "1    20 anmeldelser          --$$$$---         4,5             987   \n",
       "2    52 anmeldelser  --$$-$$$---------         4,0             980   \n",
       "3    10 anmeldelser           --$$-$$$         4,5             981   \n",
       "4    34 anmeldelser     --$$-$$$------         4,0             964   \n",
       "\n",
       "         Price range  \n",
       "0   ------1654.-448.  \n",
       "1   ------1674.-696.  \n",
       "2        ------16,,,  \n",
       "3                     \n",
       "4  ------16120.-221.  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_data_2 = ratings_df.copy()\n",
    "#trip_data = ratings_df.copy()\n",
    "print(len(trip_data_2))\n",
    "trip_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data_2.to_csv(\"Tripadvisordata_raw_xxx.csv\", index=False)\n",
    "\n",
    "ratings_df = pd.read_csv(\"Tripadvisordata_raw_xxx.csv\")\n",
    "#trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Distance from Kgs. Nytorv'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-0fb34b4f0a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mratings_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Distance from Kgs. Nytorv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4964\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4965\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Distance from Kgs. Nytorv'] not found in axis\""
     ]
    }
   ],
   "source": [
    "ratings_df = ratings_df.drop(['Distance from Kgs. Nytorv'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>God pris</th>\n",
       "      <th>Mad</th>\n",
       "      <th>Name</th>\n",
       "      <th>Service</th>\n",
       "      <th>Stemning</th>\n",
       "      <th>Location</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Price class</th>\n",
       "      <th>Main rating</th>\n",
       "      <th>Ranking on list</th>\n",
       "      <th>Price range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Bistro Central</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.68168,12.582247</td>\n",
       "      <td>50 anmeldelser</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>973</td>\n",
       "      <td>------1654.-448.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Louises Fiskebar</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.677296,12.567593</td>\n",
       "      <td>20 anmeldelser</td>\n",
       "      <td>--$$$$---</td>\n",
       "      <td>4,5</td>\n",
       "      <td>987</td>\n",
       "      <td>------1674.-696.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Café René</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.676224,12.56407</td>\n",
       "      <td>52 anmeldelser</td>\n",
       "      <td>--$$-$$$---------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>980</td>\n",
       "      <td>------16,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Herkules Pavillonen</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.68627,12.580382</td>\n",
       "      <td>10 anmeldelser</td>\n",
       "      <td>--$$-$$$</td>\n",
       "      <td>4,5</td>\n",
       "      <td>981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Galathea Kroen</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.6766,12.57455</td>\n",
       "      <td>34 anmeldelser</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>964</td>\n",
       "      <td>------16120.-221.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   God pris   Mad                 Name  Service  Stemning  \\\n",
       "0      40.0  40.0       Bistro Central     45.0       NaN   \n",
       "1      35.0  40.0     Louises Fiskebar     45.0       NaN   \n",
       "2      35.0  35.0            Café René     40.0      40.0   \n",
       "3      40.0  45.0  Herkules Pavillonen     45.0       NaN   \n",
       "4      35.0  35.0       Galathea Kroen     35.0       NaN   \n",
       "\n",
       "              Location Number of reviews        Price class Main rating  \\\n",
       "0   55.68168,12.582247    50 anmeldelser     --$$-$$$------         4,0   \n",
       "1  55.677296,12.567593    20 anmeldelser          --$$$$---         4,5   \n",
       "2   55.676224,12.56407    52 anmeldelser  --$$-$$$---------         4,0   \n",
       "3   55.68627,12.580382    10 anmeldelser           --$$-$$$         4,5   \n",
       "4     55.6766,12.57455    34 anmeldelser     --$$-$$$------         4,0   \n",
       "\n",
       "   Ranking on list        Price range  \n",
       "0              973   ------1654.-448.  \n",
       "1              987   ------1674.-696.  \n",
       "2              980        ------16,,,  \n",
       "3              981                NaN  \n",
       "4              964  ------16120.-221.  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kgs_Nytorv = '55.679977,12.5841893' #longitude and latitude for Kongens Nytorv\n",
    "\n",
    "#calculating distance from nytorv to the coordinates in the list\n",
    "def distance(x):\n",
    "    Start = ratings_df[\"Location\"][x]\n",
    "    Stop = Kgs_Nytorv\n",
    "    distance_list.append(great_circle(Start, Stop).meters)\n",
    "    \n",
    "for x in ratings_df.index:\n",
    "    distance(x)\n",
    "    \n",
    "#appending to df \n",
    "ratings_df[\"Distance from Kgs. Nytorv\"] = distance_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>God pris</th>\n",
       "      <th>Mad</th>\n",
       "      <th>Name</th>\n",
       "      <th>Service</th>\n",
       "      <th>Stemning</th>\n",
       "      <th>Location</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Price class</th>\n",
       "      <th>Main rating</th>\n",
       "      <th>Ranking on list</th>\n",
       "      <th>Price range</th>\n",
       "      <th>Distance from Kgs. Nytorv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Bistro Central</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.68168,12.582247</td>\n",
       "      <td>50 anmeldelser</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>973</td>\n",
       "      <td>------1654.-448.</td>\n",
       "      <td>225.136269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Louises Fiskebar</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.677296,12.567593</td>\n",
       "      <td>20 anmeldelser</td>\n",
       "      <td>--$$$$---</td>\n",
       "      <td>4,5</td>\n",
       "      <td>987</td>\n",
       "      <td>------1674.-696.</td>\n",
       "      <td>1082.378143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Café René</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.676224,12.56407</td>\n",
       "      <td>52 anmeldelser</td>\n",
       "      <td>--$$-$$$---------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>980</td>\n",
       "      <td>------16,,,</td>\n",
       "      <td>1328.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Herkules Pavillonen</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.68627,12.580382</td>\n",
       "      <td>10 anmeldelser</td>\n",
       "      <td>--$$-$$$</td>\n",
       "      <td>4,5</td>\n",
       "      <td>981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>739.334846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Galathea Kroen</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.6766,12.57455</td>\n",
       "      <td>34 anmeldelser</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>4,0</td>\n",
       "      <td>964</td>\n",
       "      <td>------16120.-221.</td>\n",
       "      <td>711.505212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   God pris   Mad                 Name  Service  Stemning  \\\n",
       "0      40.0  40.0       Bistro Central     45.0       NaN   \n",
       "1      35.0  40.0     Louises Fiskebar     45.0       NaN   \n",
       "2      35.0  35.0            Café René     40.0      40.0   \n",
       "3      40.0  45.0  Herkules Pavillonen     45.0       NaN   \n",
       "4      35.0  35.0       Galathea Kroen     35.0       NaN   \n",
       "\n",
       "              Location Number of reviews        Price class Main rating  \\\n",
       "0   55.68168,12.582247    50 anmeldelser     --$$-$$$------         4,0   \n",
       "1  55.677296,12.567593    20 anmeldelser          --$$$$---         4,5   \n",
       "2   55.676224,12.56407    52 anmeldelser  --$$-$$$---------         4,0   \n",
       "3   55.68627,12.580382    10 anmeldelser           --$$-$$$         4,5   \n",
       "4     55.6766,12.57455    34 anmeldelser     --$$-$$$------         4,0   \n",
       "\n",
       "   Ranking on list        Price range  Distance from Kgs. Nytorv  \n",
       "0              973   ------1654.-448.                 225.136269  \n",
       "1              987   ------1674.-696.                1082.378143  \n",
       "2              980        ------16,,,                1328.647000  \n",
       "3              981                NaN                 739.334846  \n",
       "4              964  ------16120.-221.                 711.505212  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df[['Name', 'Main rating', 'Ranking on list', 'Price range', 'Price class', 'Number of reviews', 'Location', 'Distance from Kgs. Nytorv' , 'God pris', 'Mad', 'Service', 'Stemning']]\n",
    "ratings_df = ratings_df.replace(regex=['&amp;'], value='&')\n",
    "ratings_df['Main rating'] = ratings_df['Main rating'].replace(regex=[','], value='.')\n",
    "ratings_df_new['Main rating'] = ratings_df_new['Main rating'].replace(regex=[','], value='.')\n",
    "ratings_df['Distance from Kgs. Nytorv'] = ratings_df['Distance from Kgs. Nytorv'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['Good price'] = ratings_df['God pris'] / 10\n",
    "ratings_df['Food'] = ratings_df['Mad'] / 10\n",
    "ratings_df['Service'] = ratings_df['Service'] / 10\n",
    "ratings_df['Atmosphere'] = ratings_df['Stemning'] / 10\n",
    "ratings_df = ratings_df.drop(['God pris', 'Mad', 'Stemning'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Main rating</th>\n",
       "      <th>Ranking on list</th>\n",
       "      <th>Price range</th>\n",
       "      <th>Price class</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Location</th>\n",
       "      <th>Distance from Kgs. Nytorv</th>\n",
       "      <th>Service</th>\n",
       "      <th>Good price</th>\n",
       "      <th>Food</th>\n",
       "      <th>Atmosphere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bistro Central</td>\n",
       "      <td>4.0</td>\n",
       "      <td>973</td>\n",
       "      <td>------1654.-448.</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>50 anmeldelser</td>\n",
       "      <td>55.68168,12.582247</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louises Fiskebar</td>\n",
       "      <td>4.5</td>\n",
       "      <td>987</td>\n",
       "      <td>------1674.-696.</td>\n",
       "      <td>--$$$$---</td>\n",
       "      <td>20 anmeldelser</td>\n",
       "      <td>55.677296,12.567593</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Café René</td>\n",
       "      <td>4.0</td>\n",
       "      <td>980</td>\n",
       "      <td>------16,,,</td>\n",
       "      <td>--$$-$$$---------</td>\n",
       "      <td>52 anmeldelser</td>\n",
       "      <td>55.676224,12.56407</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herkules Pavillonen</td>\n",
       "      <td>4.5</td>\n",
       "      <td>981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--$$-$$$</td>\n",
       "      <td>10 anmeldelser</td>\n",
       "      <td>55.68627,12.580382</td>\n",
       "      <td>739.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Galathea Kroen</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964</td>\n",
       "      <td>------16120.-221.</td>\n",
       "      <td>--$$-$$$------</td>\n",
       "      <td>34 anmeldelser</td>\n",
       "      <td>55.6766,12.57455</td>\n",
       "      <td>712.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Main rating  Ranking on list        Price range  \\\n",
       "0       Bistro Central         4.0              973   ------1654.-448.   \n",
       "1     Louises Fiskebar         4.5              987   ------1674.-696.   \n",
       "2            Café René         4.0              980        ------16,,,   \n",
       "3  Herkules Pavillonen         4.5              981                NaN   \n",
       "4       Galathea Kroen         4.0              964  ------16120.-221.   \n",
       "\n",
       "         Price class Number of reviews             Location  \\\n",
       "0     --$$-$$$------    50 anmeldelser   55.68168,12.582247   \n",
       "1          --$$$$---    20 anmeldelser  55.677296,12.567593   \n",
       "2  --$$-$$$---------    52 anmeldelser   55.676224,12.56407   \n",
       "3           --$$-$$$    10 anmeldelser   55.68627,12.580382   \n",
       "4     --$$-$$$------    34 anmeldelser     55.6766,12.57455   \n",
       "\n",
       "   Distance from Kgs. Nytorv  Service  Good price  Food  Atmosphere  \n",
       "0                      225.0      4.5         4.0   4.0         NaN  \n",
       "1                     1082.0      4.5         3.5   4.0         NaN  \n",
       "2                     1329.0      4.0         3.5   3.5         4.0  \n",
       "3                      739.0      4.5         4.0   4.5         NaN  \n",
       "4                      712.0      3.5         3.5   3.5         NaN  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.to_csv(\"Tripadvisordata_1000_1200.csv\", index=False)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_1 = pd.read_csv(\"Tripadvisordata_1000.csv\")\n",
    "ratings_df_2 = pd.read_csv(\"Tripadvisordata_1000_1200.csv\")\n",
    "ratings_df_1 = ratings_df_1.append(ratings_df_2)\n",
    "ratings_df_1.to_csv(\"Tripadvisordata_1200.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
