{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_class\n",
    "import pandas as pd\n",
    "import requests,os,time\n",
    "from datetime import datetime\n",
    "\n",
    "logfile=\"trustpilot.txt\"\n",
    "Connector = scraping_class.Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,os,time\n",
    "\n",
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(1) # sleep one second.\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='requests',session=False,path2selenium='',n_tries = 5,timeout=30):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring. \n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessments\n",
    "    \n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case). \n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver \n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Firefox(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "    \n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\n",
    "    header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "    if os.path.isfile(logfile):        \n",
    "      if overwrite_log==True:\n",
    "        self.log = open(logfile,'w')\n",
    "        self.log.write(';'.join(header))\n",
    "      else:\n",
    "        self.log = open(logfile,'a')\n",
    "    else:\n",
    "      self.log = open(logfile,'w')\n",
    "      self.log.write(';'.join(header))\n",
    "    ## load log \n",
    "    with open(logfile,'r') as f: # open file\n",
    "        \n",
    "      l = f.read().split('\\n') # read and split file by newlines.\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1][0])+1\n",
    "            \n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, Name used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    "     \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit()\n",
    "        t = time.time()\n",
    "        try: # error handling \n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = t - time.time() # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          call_id = self.id # get current unique identifier for the call\n",
    "          self.id+=1 # increment call id\n",
    "          #['id','project_name','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row to be written in the log.\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write log.\n",
    "          return response,call_id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt = t - time.time() # define delta t\n",
    "\n",
    "          ## log...\n",
    "          call_id = self.id # define unique identifier\n",
    "          self.id+=1 # increment call_id\n",
    "\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write row to log.\n",
    "    else:\n",
    "      t = time.time()\n",
    "      ratelimit()\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      ## log\n",
    "      call_id = self.id # define unique identifier for the call. \n",
    "      self.id+=1 # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = t - time.time() # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row \n",
    "      self.log.write('\\n'+';'.join(map(str,row))) # write row to log file.\n",
    "    # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "    ## connector.browser.page_source will give you the html.\n",
    "      return call_id\n",
    "    \n",
    "\n",
    "logfile=\"trustpilot.txt\" ## name your log file.\n",
    "connector = Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 2019-08-23 10:17:02.275424\n",
      "True 2019-08-23 10:17:04.191196\n",
      "True 2019-08-23 10:17:06.018419\n",
      "True 2019-08-23 10:17:07.724592\n",
      "True 2019-08-23 10:17:09.539219\n",
      "True 2019-08-23 10:17:11.245126\n",
      "True 2019-08-23 10:17:12.907775\n",
      "True 2019-08-23 10:17:14.675153\n",
      "True 2019-08-23 10:17:16.364732\n",
      "True 2019-08-23 10:17:18.183558\n",
      "True 2019-08-23 10:17:19.880984\n",
      "True 2019-08-23 10:17:21.629245\n",
      "True 2019-08-23 10:17:23.313286\n",
      "True 2019-08-23 10:17:25.052775\n",
      "True 2019-08-23 10:17:26.761338\n",
      "True 2019-08-23 10:17:28.642588\n",
      "True 2019-08-23 10:17:30.478554\n",
      "True 2019-08-23 10:17:32.745052\n",
      "True 2019-08-23 10:17:34.494954\n",
      "True 2019-08-23 10:17:36.240835\n",
      "True 2019-08-23 10:17:38.155164\n",
      "True 2019-08-23 10:17:40.015859\n",
      "True 2019-08-23 10:17:41.759176\n",
      "True 2019-08-23 10:17:43.985840\n",
      "True 2019-08-23 10:17:45.672584\n",
      "True 2019-08-23 10:17:47.463255\n",
      "True 2019-08-23 10:17:49.261980\n",
      "True 2019-08-23 10:17:51.029574\n",
      "True 2019-08-23 10:17:52.672574\n",
      "True 2019-08-23 10:17:54.360619\n",
      "True 2019-08-23 10:17:56.076870\n",
      "True 2019-08-23 10:17:57.958085\n",
      "True 2019-08-23 10:17:59.635771\n",
      "True 2019-08-23 10:18:01.413848\n",
      "True 2019-08-23 10:18:03.148562\n",
      "True 2019-08-23 10:18:04.841513\n",
      "True 2019-08-23 10:18:06.543100\n",
      "True 2019-08-23 10:18:08.297960\n",
      "True 2019-08-23 10:18:10.038133\n",
      "True 2019-08-23 10:18:11.722702\n",
      "True 2019-08-23 10:18:13.915136\n",
      "True 2019-08-23 10:18:15.609065\n",
      "True 2019-08-23 10:18:17.316575\n",
      "True 2019-08-23 10:18:19.489025\n",
      "True 2019-08-23 10:18:21.316751\n",
      "True 2019-08-23 10:18:23.114118\n",
      "True 2019-08-23 10:18:25.357345\n",
      "True 2019-08-23 10:18:27.277526\n",
      "True 2019-08-23 10:18:29.171068\n",
      "True 2019-08-23 10:18:30.868718\n",
      "True 2019-08-23 10:18:32.587279\n",
      "True 2019-08-23 10:18:34.280300\n",
      "True 2019-08-23 10:18:36.044509\n",
      "True 2019-08-23 10:18:37.888243\n",
      "True 2019-08-23 10:18:39.612044\n",
      "True 2019-08-23 10:18:41.848310\n",
      "True 2019-08-23 10:18:43.626356\n",
      "True 2019-08-23 10:18:45.299802\n",
      "True 2019-08-23 10:18:47.054105\n",
      "True 2019-08-23 10:18:48.745684\n",
      "True 2019-08-23 10:18:50.429148\n",
      "True 2019-08-23 10:18:52.099554\n",
      "True 2019-08-23 10:18:53.795319\n",
      "True 2019-08-23 10:18:55.506342\n",
      "True 2019-08-23 10:18:57.252133\n",
      "True 2019-08-23 10:18:58.958475\n",
      "True 2019-08-23 10:19:00.606972\n",
      "True 2019-08-23 10:19:02.587414\n",
      "True 2019-08-23 10:19:04.253783\n",
      "True 2019-08-23 10:19:06.005489\n",
      "True 2019-08-23 10:19:07.722722\n",
      "True 2019-08-23 10:19:09.459837\n",
      "True 2019-08-23 10:19:11.200102\n",
      "True 2019-08-23 10:19:12.944101\n",
      "True 2019-08-23 10:19:14.626883\n",
      "True 2019-08-23 10:19:16.329105\n",
      "True 2019-08-23 10:19:18.014647\n",
      "True 2019-08-23 10:19:19.741018\n"
     ]
    }
   ],
   "source": [
    "url_init = 'https://www.tripadvisor.com' # base url\n",
    "max_restaurant = 2322\n",
    "init_number = 0\n",
    "final_urls = []\n",
    "\n",
    "while init_number <= max_restaurant:\n",
    "    timestamp = datetime.now() # Creates a timestamp in the format yyyy-mm-dd h:m:s\n",
    "    \n",
    "    url_search = '/RestaurantSearch-g189541-o' # first part of url\n",
    "    url_search2 = '-a_date.2019__2D__08__2D__22-a_people.2-a_time.20%3A00%3A00-a_zur.2019__5F__08__5F__22-Copenhag.html#EATERY_LIST_CONTENTS' # second part of url\n",
    "    url_search3 = url_init + url_search + str(init_number) + url_search2 # combined dynamic url\n",
    "    data, call_id = connector.get(url_search3, 'exam') # gathering data\n",
    "    response = data.ok # check if data is available\n",
    "    print(response, timestamp) # prints response and timestamp of call.\n",
    "    final_urls.append(url_search3)\n",
    "    init_number += 30 # incriments the number by 30 to be put into the url next call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "#print(init_number)\n",
    "print(len(final_urls))\n",
    "#df = pd.DataFrame(final_urls)\n",
    "#pd.options.display.max_colwidth = 200\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2319"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_list = []\n",
    "for url in final_urls: # loops over all overview sites \n",
    "    response,call_id = connector.get(url,'course_mapping')\n",
    "    link_locations = response.text.split('href=\"')[1:] # find all links on site \n",
    "    liste = [] \n",
    "\n",
    "    for i in link_locations:\n",
    "        if \"Restaurant_Review\" in i: # finds all links named something with Restaurant review \n",
    "            liste.append(i.partition(\" \")[0])\n",
    "\n",
    "    review_list=  []\n",
    "    for i in liste:\n",
    "        if \"Restaurant_Review\" in i and \"#REVIEWS\" not in i and \"button\" not in i: # same link appars more times this loop removes two alternative versions\n",
    "            review_list.append(i)\n",
    "    \n",
    "    review_list_u = set(review_list) # remove dublicates\n",
    "      \n",
    "    url_part_1 = \"https://www.tripadvisor.com/\"  # this is the baseline part of a link\n",
    "\n",
    "    for i in review_list_u:\n",
    "        page_list.append(url_part_1+i) # make list of final urls\n",
    "        \n",
    "len(page_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_final_urls = pd.DataFrame(page_list)\n",
    "pd.options.display.max_colwidth = 200\n",
    "#print(fin_final_urls[887])\n",
    "#fin_final_urls.to_csv(\"page_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_final_urls = fin_final_urls.replace({'\\\"':''}, regex = True) # deletes qutationmarks\n",
    "\n",
    "fin_final_urls.to_csv(\"page_urls.csv\") # prints to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.tripadvisor.com//Restaurant_Review-g189541-d15804886-Reviews-The_Pescatarian-Copenhagen_Zealand.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.tripadvisor.com//Restaurant_Review-g189541-d13979688-Reviews-Trattoria_SUD-Copenhagen_Zealand.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.tripadvisor.com//Restaurant_Review-g806262-d1604419-Reviews-Enomania-Frederiksberg_Copenhagen_Zealand.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.tripadvisor.com//Restaurant_Review-g189541-d1945657-Reviews-Geranium-Copenhagen_Zealand.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.tripadvisor.com//Restaurant_Review-g189541-d12454509-Reviews-Garden_Restaurant_Bar-Copenhagen_Zealand.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        0\n",
       "0        https://www.tripadvisor.com//Restaurant_Review-g189541-d15804886-Reviews-The_Pescatarian-Copenhagen_Zealand.html\n",
       "1          https://www.tripadvisor.com//Restaurant_Review-g189541-d13979688-Reviews-Trattoria_SUD-Copenhagen_Zealand.html\n",
       "2  https://www.tripadvisor.com//Restaurant_Review-g806262-d1604419-Reviews-Enomania-Frederiksberg_Copenhagen_Zealand.html\n",
       "3                https://www.tripadvisor.com//Restaurant_Review-g189541-d1945657-Reviews-Geranium-Copenhagen_Zealand.html\n",
       "4  https://www.tripadvisor.com//Restaurant_Review-g189541-d12454509-Reviews-Garden_Restaurant_Bar-Copenhagen_Zealand.html"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_final_urls.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
